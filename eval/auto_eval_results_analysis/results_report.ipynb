{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed3a84f5-fe7c-4d82-8f48-324d8919d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from ydata_profiling import ProfileReport\n",
    "import seaborn as sns\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "534ef5d6-e993-4713-a09b-af07f9d180ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result = pd.read_csv('', index_col = False)\n",
    "# print(df_result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cece9cc-67b8-4c75-9b62-9e66704bcdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result = df_result.loc[:, ~df_result.columns.str.contains('^Unnamed')]\n",
    "# df = df.drop(columns=[col for col in df.columns if 'Unnamed' in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19e49205-5b24-4382-a4bb-90990bf15bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df91dd29-6e73-4b80-934d-67695af498f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result.to_csv(f'automatic_eval_res.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a5cc8b-998d-44f0-9094-c34ad33652c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = ProfileReport(df_result, title=\"Profiling Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b1165d4-4482-4973-b6d9-badbd949fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "195372d5-e122-484d-8acc-437a343d0fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language Methodology   ACC    CS  BLEU    PPL   AVG\n",
      "0       en    Parallel  79.5  81.5  46.5  102.3  69.2\n",
      "1       en          AE   7.5  78.0  42.0  102.3  42.5\n",
      "2       en          BT  27.0  65.5  11.5  118.0  34.7\n",
      "3       en      MSF-AE  64.5  72.5  36.0  200.2  57.7\n",
      "4       en      MSF-BT  67.0  56.5   8.0   65.7  43.8\n"
     ]
    }
   ],
   "source": [
    "df_result = pd.read_csv('automatic_eval_res.csv')\n",
    "print(df_result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2688cee5-a6a7-44b3-a50c-3746a59d2967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Bar Chart: Average Scores Across Languages\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Language', y='AVG', data=df_result, errorbar=None)\n",
    "plt.title('Average Scores Across Languages')\n",
    "# plt.show()\n",
    "\n",
    "save_path = os.path.join('figs/', f'avg.png')\n",
    "plt.savefig(save_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2afaed1c-5de5-4a01-8768-0cccd65867b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Heatmap: Sentiment Accuracy, Similarity, BLEU Score, and PPL\n",
    "metrics = ['ACC', 'CS', 'BLEU', 'PPL']\n",
    "\n",
    "for metric in metrics:\n",
    "    pivot_table = df_result.pivot_table(index='Language', columns='Methodology', values=metric)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(pivot_table, annot=True, cmap='coolwarm', center=pivot_table.stack().mean())\n",
    "    plt.title(f'Heatmap of {metric} by Language and Methodology')\n",
    "    # plt.show()\n",
    "    save_path = os.path.join('figs/', f'heatmap_{metric}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88607d6d-34e5-479c-a526-d765a8867bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Line Chart: Performance of Different Models\n",
    "models = df_result['Methodology'].unique()\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for model in models:\n",
    "        model_data = df_result[df_result['Methodology'] == model]\n",
    "        sns.lineplot(x='Language', y=metric, data=model_data, label=model)\n",
    "    plt.title(f'Performance of Models Across Languages for {metric}')\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "    save_path = os.path.join('figs/', f'linechart_{metric}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ffe5218-4003-49f0-af60-d274329326ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2431251/876731639.py:7: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Language', y=metric, hue='Methodology', data=df_result[df_result['Language'].isin(resource_rich + low_resource.tolist())], ci=None)\n",
      "/tmp/ipykernel_2431251/876731639.py:7: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Language', y=metric, hue='Methodology', data=df_result[df_result['Language'].isin(resource_rich + low_resource.tolist())], ci=None)\n",
      "/tmp/ipykernel_2431251/876731639.py:7: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Language', y=metric, hue='Methodology', data=df_result[df_result['Language'].isin(resource_rich + low_resource.tolist())], ci=None)\n",
      "/tmp/ipykernel_2431251/876731639.py:7: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Language', y=metric, hue='Methodology', data=df_result[df_result['Language'].isin(resource_rich + low_resource.tolist())], ci=None)\n"
     ]
    }
   ],
   "source": [
    "# 4. Grouped Bar Chart: English and Hindi vs. Low-Resource Languages\n",
    "resource_rich = ['en', 'hi']\n",
    "low_resource = df_result[~df_result['Language'].isin(resource_rich)]['Language'].unique()\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.barplot(x='Language', y=metric, hue='Methodology', data=df_result[df_result['Language'].isin(resource_rich + low_resource.tolist())], ci=None)\n",
    "    plt.title(f'{metric} for Resource-Rich vs. Low-Resource Languages')\n",
    "    # plt.show()\n",
    "    save_path = os.path.join('figs/', f'groupedbar_{metric}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "687ea3c9-c6d8-4ac0-868a-82036f34d194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2431251/2948638796.py:7: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Language', y=metric, hue='Methodology', data=df_result[df_result['Methodology'].isin(masking_methods + non_masking_methods)], ci=None)\n",
      "/tmp/ipykernel_2431251/2948638796.py:7: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Language', y=metric, hue='Methodology', data=df_result[df_result['Methodology'].isin(masking_methods + non_masking_methods)], ci=None)\n",
      "/tmp/ipykernel_2431251/2948638796.py:7: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Language', y=metric, hue='Methodology', data=df_result[df_result['Methodology'].isin(masking_methods + non_masking_methods)], ci=None)\n",
      "/tmp/ipykernel_2431251/2948638796.py:7: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Language', y=metric, hue='Methodology', data=df_result[df_result['Methodology'].isin(masking_methods + non_masking_methods)], ci=None)\n"
     ]
    }
   ],
   "source": [
    "# 5. Clustered Bar Chart: Masking vs. Non-Masking Methodologies\n",
    "masking_methods = ['MSF-AE', 'MSF-BT']\n",
    "non_masking_methods = ['AE', 'BT']\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.barplot(x='Language', y=metric, hue='Methodology', data=df_result[df_result['Methodology'].isin(masking_methods + non_masking_methods)], ci=None)\n",
    "    plt.title(f'Impact of Masking Techniques on {metric}')\n",
    "    # plt.show()\n",
    "    save_path = os.path.join('figs/', f'clusteredbar_{metric}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c318234-4e60-4a36-8c2a-31e4ce8a636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Stacked Bar Chart: Performance of Models for Each Language\n",
    "languages = df_result['Language'].unique()\n",
    "for language in languages:\n",
    "    language_data = df_result[df_result['Language'] == language]\n",
    "    language_data.set_index('Methodology')[metrics].T.plot(kind='bar', stacked=True, figsize=(14, 8))\n",
    "    plt.title(f'Performance of Models for {language}')\n",
    "    # plt.show()\n",
    "    save_path = os.path.join('figs/', f'stackedbar_{language}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1a46cae-0fda-4cd3-814d-37cd5de6f633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Box Plot: Distribution of Specific Metrics Across Languages\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.boxplot(x='Language', y=metric, data=df_result)\n",
    "    plt.title(f'Distribution of {metric} Across Languages')\n",
    "    # plt.show()\n",
    "    save_path = os.path.join('figs/', f'boxplot_{metric}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21339f4d-de80-47b3-b53d-b2d430b2e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Line Chart: Indo-Aryan vs. Dravidian Languages\n",
    "indo_aryan = ['en', 'hi', 'mag', 'mr', 'or', 'pa', 'ur']\n",
    "dravidian = ['ml', 'te']\n",
    "\n",
    "metrics = ['ACC', 'CS', 'BLEU', 'PPL']\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    indo_aryan_data = df_result[df_result['Language'].isin(indo_aryan)]\n",
    "    sns.lineplot(x='Language', y=metric, hue='Methodology', data=indo_aryan_data, marker='o')\n",
    "    \n",
    "    dravidian_data = df_result[df_result['Language'].isin(dravidian)]\n",
    "    sns.lineplot(x='Language', y=metric, hue='Methodology', data=dravidian_data, marker='s', linestyle='--')\n",
    "    \n",
    "    plt.title(f'Performance of Indo-Aryan vs. Dravidian Languages for {metric}')\n",
    "    plt.legend(title='Methodology', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xlabel('Language')\n",
    "    plt.ylabel(metric)\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    save_path = os.path.join('figs/', f'linechart_indovsdrav_{metric}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a2f3bb4-31f0-4504-aadc-60b48b5f39ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for language: en, methodology: En-IP-TR-Train\n",
      "No data for language: en, methodology: En-Op-Tr\n"
     ]
    }
   ],
   "source": [
    "languages = df_result['Language'].unique()\n",
    "methodologies = df_result['Methodology'].unique()\n",
    "categories = ['ACC', 'CS', 'BLEU', 'PPL']\n",
    "num_vars = len(categories)\n",
    "\n",
    "for language in languages:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "\n",
    "    for methodology in methodologies:\n",
    "        subset = df_result[(df_result['Language'] == language) & (df_result['Methodology'] == methodology)]\n",
    "        if subset.empty:\n",
    "            print(f\"No data for language: {language}, methodology: {methodology}\")\n",
    "            continue\n",
    "        values = subset[categories].values.flatten().tolist()\n",
    "        if len(values) == 0:\n",
    "            print(f\"No metric values for language: {language}, methodology: {methodology}\")\n",
    "            continue\n",
    "        values += values[:1]\n",
    "        ax.plot(angles, values, label=methodology)\n",
    "        ax.fill(angles, values, alpha=0.25)\n",
    "\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(categories)\n",
    "    plt.title(f'Radar Chart of Methodologies for {language}')\n",
    "    plt.legend()\n",
    "\n",
    "    save_path = os.path.join('figs/', f'radarchart_{language}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baaf9984-28d3-4930-a48b-d81cc230ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Scatter Plot: Sentiment Accuracy vs. BLEU Score\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.scatterplot(x='ACC', y='BLEU', hue='Language', style='Methodology', data=df_result)\n",
    "plt.title('Sentiment Accuracy vs. BLEU Score')\n",
    "# plt.show()\n",
    "save_path = os.path.join('figs/', f'scatter_accvsbleu.png')\n",
    "plt.savefig(save_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c3f1842-bf7c-48ff-8017-da9fd987b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Scatter Plot: Sentiment Accuracy vs. Similarity\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.scatterplot(x='ACC', y='CS', hue='Language', style='Methodology', data=df_result)\n",
    "plt.title('Sentiment Accuracy vs. CS Score')\n",
    "# plt.show()\n",
    "save_path = os.path.join('figs/', f'scatter_accvscs.png')\n",
    "plt.savefig(save_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e33ce9fc-93a1-4391-812d-13c11763553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Scatter Plot: Bleu score vs. Similarity\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.scatterplot(x='BLEU', y='CS', hue='Language', style='Methodology', data=df_result)\n",
    "plt.title('BLEU vs. CS Score')\n",
    "# plt.show()\n",
    "save_path = os.path.join('figs/', f'scatter_bleuvscs.png')\n",
    "plt.savefig(save_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2135c817-8f27-476f-a4ab-805717fb3a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. analysis between the categories of methodologies\n",
    "methodology_categories = {\n",
    "    'Parallel': ['Parallel'],\n",
    "    'Non-parallel': ['AE', 'BT', 'MSF-AE', 'MSF-BT'],\n",
    "    'Cross-Lingual': ['En-IP-TR-Train','En-OP-TR'],\n",
    "    'Shared Learning Joint': ['Joint'],\n",
    "    'Large Language Models': ['Llama2', 'Llama2_chat', 'GPT3.5']\n",
    "}\n",
    "\n",
    "category_data = []\n",
    "\n",
    "for category, methodologies in methodology_categories.items():\n",
    "    category_data.extend([(category, methodology, metric, value)\n",
    "                          for methodology in methodologies\n",
    "                          for metric, values in category_metrics[category].items()\n",
    "                          for value in values])\n",
    "\n",
    "df_category = pd.DataFrame(category_data, columns=['Category', 'Methodology', 'Metric', 'Value'])\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df_category[df_category['Metric'] == metric], x='Category', y='Value', hue='Methodology')\n",
    "    plt.title(f'Comparison of {metric} across Methodology Categories')\n",
    "    plt.xlabel('Methodology Category')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Methodology', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    save_path = os.path.join('figs/', f'category_{metric}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb1c8d9-a2f5-4662-b0fc-eed2e4e17faf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
